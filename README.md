# ViT_TensorRT_Inference_Optimization
Inference optimization of the BERT model using TensorRT, NVIDIA's high-performance deep learning inference platform. TensorRT is designed to maximize the efficiency of deep learning models during inference, particularly on NVIDIA GPUs. By integrating TensorRT with ViT, we aim to significantly enhance the speed, efficiency, and performance of ViT
